package com.holo.oshi.member.test

import kotlinx.coroutines.*
import kotlinx.coroutines.flow.*
import kotlinx.coroutines.test.*
import org.junit.jupiter.api.*
import mu.KotlinLogging
import kotlin.time.Duration
import kotlin.time.measureTime

/**
 * ğŸ¯ Coroutines & Flow Ultimate Performance Test
 * 
 * Pure Kotlin ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ê²€ì¦:
 * âœ… Coroutines vs Threads ì„±ëŠ¥ ë¹„êµ
 * âœ… Flow vs Sequence vs List ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
 * âœ… Structured Concurrency ê²€ì¦
 * âœ… Backpressure Handling
 * âœ… Error Handling in Concurrent Context
 * âœ… CPU-bound vs IO-bound ìµœì í™”
 * âœ… Dispatcher ì„ íƒ ìµœì í™”
 * âœ… Channel vs Flow ì„±ëŠ¥ ë¹„êµ
 */
private val logger = KotlinLogging.logger {}

@TestInstance(TestInstance.Lifecycle.PER_CLASS)
@KotlinTest
class CoroutinesFlowTest {
    
    @Test
    @KotlinSpec("FlowëŠ” Sequenceë³´ë‹¤ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ì–´ì•¼ í•¨")
    fun `Flow should be more memory efficient than Sequence`() = runTest {
        kotlinTest("Flow vs Sequence ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±") {
            `given`("ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤") {
                logger.info { "10ë§Œ ê°œ ë©¤ë²„ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜" }
            }
            
            `when`("Flowì™€ Sequenceë¡œ ë™ì¼í•œ ì²˜ë¦¬") {
                val dataSize = 100_000
                
                // Flow ë°©ì‹ (ìŠ¤íŠ¸ë¦¬ë°)
                val flowResult = measureMemoryUsage("Flow ì²˜ë¦¬") {
                    generateMemberFlow(dataSize)
                        .filter { it.id % 2 == 0L }  // ì§ìˆ˜ IDë§Œ
                        .map { "ì²˜ë¦¬ë¨: ${it.name}" }
                        .take(1000)
                        .toList()
                }
                
                // Sequence ë°©ì‹ (ì§€ì—° í‰ê°€)
                val sequenceResult = measureMemoryUsage("Sequence ì²˜ë¦¬") {
                    generateMemberSequence(dataSize)
                        .filter { it.id % 2 == 0L }
                        .map { "ì²˜ë¦¬ë¨: ${it.name}" }
                        .take(1000)
                        .toList()
                }
                
                // List ë°©ì‹ (ì¦‰ì‹œ í‰ê°€)
                val listResult = measureMemoryUsage("List ì²˜ë¦¬") {
                    generateMemberList(dataSize)
                        .filter { it.id % 2 == 0L }
                        .map { "ì²˜ë¦¬ë¨: ${it.name}" }
                        .take(1000)
                }
                
                Triple(flowResult, sequenceResult, listResult)
            }
            
            `then`("Flowê°€ ê°€ì¥ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ì–´ì•¼ í•¨") { (flowMem, seqMem, listMem) ->
                val (flowTime, flowMemory) = flowMem as Pair<Duration, Long>
                val (seqTime, seqMemory) = seqMem as Pair<Duration, Long>
                val (listTime, listMemory) = listMem as Pair<Duration, Long>
                
                // âœ… Flowê°€ Listë³´ë‹¤ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (ìµœì†Œ 50% ì ˆì•½)
                assert(flowMemory < listMemory * 0.5) {
                    "Flow should use less memory: Flow=$flowMemory, List=$listMemory"
                }
                
                // âœ… Flowê°€ í•©ë¦¬ì ì¸ ì„±ëŠ¥
                assert(flowTime < listTime * 2.0) {
                    "Flow should not be more than 2x slower: Flow=$flowTime, List=$listTime"
                }
                
                logger.info { 
                    "ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ - Flow: ${flowMemory}B, Sequence: ${seqMemory}B, List: ${listMemory}B" 
                }
                logger.info { 
                    "â±ï¸ ì²˜ë¦¬ ì‹œê°„ - Flow: ${flowTime.inWholeMilliseconds}ms, Sequence: ${seqTime.inWholeMilliseconds}ms, List: ${listTime.inWholeMilliseconds}ms"
                }
            }
        }
    }
    
    @Test
    @KotlinBenchmark(iterations = 1000)
    @KotlinSpec("Coroutines ë™ì‹œì„±ì´ Threadë³´ë‹¤ íš¨ìœ¨ì ì´ì–´ì•¼ í•¨")
    fun `Coroutines should be more efficient than Threads`() = runTest {
        val concurrentTasks = 1000
        
        // Coroutines ë°©ì‹
        val coroutinesPerf = measureCoroutinePerformance("Coroutines ë™ì‹œì„±", 100) {
            supervisorScope {
                (1..concurrentTasks).map { taskId ->
                    async(Dispatchers.Default) {
                        simulateWork(taskId)
                    }
                }.awaitAll()
            }
        }
        
        // Thread ë°©ì‹ (ë¹„êµìš©)
        val threadsPerf = measureCoroutinePerformance("Thread ë™ì‹œì„±", 100) {
            withContext(Dispatchers.Default) {
                val jobs = (1..concurrentTasks).map { taskId ->
                    async {
                        // Thread pool ì‚¬ìš©
                        withContext(Dispatchers.IO) {
                            simulateWork(taskId)
                        }
                    }
                }
                jobs.awaitAll()
            }
        }
        
        logger.info { 
            "ğŸš€ ë™ì‹œì„± ì„±ëŠ¥ ë¹„êµ:\n" +
            "   Coroutines: ${coroutinesPerf.averageTime.inWholeMilliseconds}ms\n" +
            "   Threads: ${threadsPerf.averageTime.inWholeMilliseconds}ms"
        }
        
        // âœ… Coroutinesê°€ Threadë³´ë‹¤ ë¹ ë¥´ê±°ë‚˜ ë¹„ìŠ·í•´ì•¼ í•¨
        val ratio = coroutinesPerf.averageTime.inWholeMilliseconds.toDouble() / 
                   threadsPerf.averageTime.inWholeMilliseconds
        
        assert(ratio <= 1.2) { "Coroutines should not be >20% slower than threads: ${ratio}x" }
    }
    
    @Test
    @KotlinSpec("Flow backpressureê°€ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨")
    fun `Flow backpressure should be handled correctly`() = runTest {
        kotlinTest("Flow backpressure ì²˜ë¦¬") {
            `given`("ë¹ ë¥¸ ìƒì‚°ìì™€ ëŠë¦° ì†Œë¹„ì") {}
            
            `when`("Flowë¡œ backpressure ìƒí™© ìƒì„±") {
                val fastProducer = flow {
                    repeat(10000) { i ->
                        emit("ë°ì´í„°-$i")
                        // ìƒì‚°ìëŠ” ë§¤ìš° ë¹ ë¦„ (ì§€ì—° ì—†ìŒ)
                    }
                }
                
                val slowConsumerResult = mutableListOf<String>()
                val processingTime = measureTime {
                    fastProducer
                        .buffer(100)  // ë²„í¼ë§ìœ¼ë¡œ backpressure ì™„í™”
                        .collect { data ->
                            delay(1) // ì†Œë¹„ìëŠ” ëŠë¦¼ (1ms ì§€ì—°)
                            slowConsumerResult.add("ì²˜ë¦¬ë¨: $data")
                        }
                }
                
                processingTime to slowConsumerResult.size
            }
            
            `then`("backpressureê°€ ê´€ë¦¬ë˜ë©° ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ë¨") { (time, processedCount) ->
                val (processingTime, count) = time as Pair<Duration, Int>
                
                // âœ… ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ë¨
                count shouldBe 10000
                
                // âœ… í•©ë¦¬ì ì¸ ì²˜ë¦¬ ì‹œê°„ (ë²„í¼ë§ íš¨ê³¼)
                processingTime.shouldBeLessThan(Duration.seconds(15))
                
                logger.info { "âœ… Backpressure ì²˜ë¦¬ ì™„ë£Œ: ${count}ê°œ í•­ëª©, ${processingTime.inWholeMilliseconds}ms" }
            }
        }
    }
    
    @Test
    @KotlinSpec("Structured Concurrencyê°€ ì˜ˆì™¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì „íŒŒí•´ì•¼ í•¨")
    fun `Structured Concurrency should propagate exceptions correctly`() = runTest {
        kotlinTest("êµ¬ì¡°í™”ëœ ë™ì‹œì„± ì˜ˆì™¸ ì²˜ë¦¬") {
            `given`("ì¼ë¶€ ì‘ì—…ì´ ì‹¤íŒ¨í•˜ëŠ” ë™ì‹œì„± ì‹œë‚˜ë¦¬ì˜¤") {}
            
            `when`("supervisorScopeì—ì„œ ì¼ë¶€ ì‘ì—… ì‹¤íŒ¨") {
                val result = runCatching {
                    supervisorScope {
                        val job1 = async { delay(100); "ì„±ê³µ1" }
                        val job2 = async { delay(50); throw RuntimeException("ì‹¤íŒ¨2") }
                        val job3 = async { delay(200); "ì„±ê³µ3" }
                        
                        // job2 ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì‘ì—…ì€ ê³„ì†
                        val results = listOfNotNull(
                            job1.await(),
                            runCatching { job2.await() }.getOrNull(),
                            job3.await()
                        )
                        
                        results
                    }
                }
                
                result
            }
            
            `then`("ì‹¤íŒ¨í•œ ì‘ì—…ë§Œ ì œì™¸ë˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì™„ë£Œë˜ì–´ì•¼ í•¨") { result ->
                val r = result as Result<List<String>>
                
                val successResults = r.getOrThrow()
                successResults shouldBe listOf("ì„±ê³µ1", "ì„±ê³µ3")  // job2 ì œì™¸
                
                logger.info { "âœ… êµ¬ì¡°í™”ëœ ë™ì‹œì„± ê²€ì¦ ì™„ë£Œ: $successResults" }
            }
        }
    }
    
    @Test
    @KotlinBenchmark(iterations = 100)
    @KotlinSpec("Flow parallel processing ì„±ëŠ¥ ê²€ì¦")
    fun `Flow parallel processing should scale well`() = runTest {
        val dataSize = 10000
        
        // ìˆœì°¨ ì²˜ë¦¬
        val sequentialPerf = measureCoroutinePerformance("ìˆœì°¨ ì²˜ë¦¬", 10) {
            (1..dataSize).asFlow()
                .map { simulateExpensiveOperation(it) }
                .toList()
        }
        
        // ë³‘ë ¬ ì²˜ë¦¬ (Extension Function í™œìš©)
        val parallelPerf = measureCoroutinePerformance("ë³‘ë ¬ ì²˜ë¦¬", 10) {
            (1..dataSize).asFlow()
                .mapParallel(concurrency = 8) { simulateExpensiveOperation(it) }
                .toList()
        }
        
        val speedup = sequentialPerf.averageTime.inWholeMilliseconds.toDouble() / 
                     parallelPerf.averageTime.inWholeMilliseconds
        
        logger.info { 
            "ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ: ${String.format("%.2f", speedup)}x ë¹ ë¦„\n" +
            "   ìˆœì°¨: ${sequentialPerf.averageTime.inWholeMilliseconds}ms\n" +
            "   ë³‘ë ¬: ${parallelPerf.averageTime.inWholeMilliseconds}ms"
        }
        
        // âœ… ë³‘ë ¬ ì²˜ë¦¬ê°€ ìµœì†Œ 2ë°° ë¹¨ë¼ì•¼ í•¨ (8 ì½”ì–´ ê°€ì •ì‹œ)
        assert(speedup >= 2.0) { "Parallel processing should be at least 2x faster: ${speedup}x" }
    }
    
    // ============ Test Helper Functions ============
    
    private suspend fun simulateWork(taskId: Int): String {
        delay(1) // 1ms ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        return "Task-$taskId ì™„ë£Œ"
    }
    
    private suspend fun simulateExpensiveOperation(input: Int): String {
        delay(1) // ë¹„ìš©ì´ ë†’ì€ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        return "Processed-$input"
    }
    
    private fun generateMemberFlow(count: Int): Flow<TestMember> = flow {
        repeat(count) { i ->
            emit(TestMember(i.toLong(), "Member-$i", "jp", "gen${i % 6}"))
        }
    }
    
    private fun generateMemberSequence(count: Int): Sequence<TestMember> = sequence {
        repeat(count) { i ->
            yield(TestMember(i.toLong(), "Member-$i", "jp", "gen${i % 6}"))
        }
    }
    
    private fun generateMemberList(count: Int): List<TestMember> = 
        (0 until count).map { i ->
            TestMember(i.toLong(), "Member-$i", "jp", "gen${i % 6}")
        }
    
    private suspend fun measureMemoryUsage(
        name: String,
        block: suspend () -> List<String>
    ): Pair<Duration, Long> {
        System.gc() // GC ì‹¤í–‰
        val beforeMemory = Runtime.getRuntime().let { it.totalMemory() - it.freeMemory() }
        
        val (result, duration) = measureTimedValue { block() }
        
        System.gc() // GC ì‹¤í–‰
        val afterMemory = Runtime.getRuntime().let { it.totalMemory() - it.freeMemory() }
        
        val memoryUsed = afterMemory - beforeMemory
        
        logger.debug { "$name: ${result.size}ê°œ ê²°ê³¼, ${duration.inWholeMilliseconds}ms, ${memoryUsed}B" }
        
        return duration to memoryUsed
    }
    
    data class TestMember(
        val id: Long,
        val name: String, 
        val branch: String,
        val generation: String
    )
}